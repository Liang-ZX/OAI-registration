{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "sys.path.append(r'../../pykneer')\n",
    "sys.path.append(r'../pykneer')\n",
    "import pykneer_io as io\n",
    "importlib.reload(io)\n",
    "import preprocessing_for_nb as prep\n",
    "importlib.reload(prep)\n",
    "import segmentation_sa_for_nb as segm\n",
    "importlib.reload(segm)\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from preparing_images import prepare_image_and_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ahaknee0tp29  exist\n",
      "dcm path for TPid 0 Z:/OAI Baseline/ge0/9189303/10397606\n",
      "Loading QVJ Y:/0tp29\\cascade/0/9189303/10397606L\\E10397606L_L.QVJ\n",
      "Adding QVS E10397606LS101_L.QVS\n",
      "coronal Z:/OAI Baseline/ge0/9189303/10397606/001.dcm\n",
      "no such contour OuterWall\n",
      "No lumen contour for frappe dcm slice 75\n",
      "ahaknee12tp29  exist\n",
      "dcm path for TPid 1 Z:/OAI 12 Months/2.C.2/9189303/20060522/11151205\n",
      "Loading QVJ Y:/12tp29\\cascade/12/9189303/20060522L\\E20060522L_L.QVJ\n",
      "Adding QVS E20060522LS101_L.QVS\n",
      "coronal Z:/OAI 12 Months/2.C.2/9189303/20060522/11151205/001.dcm\n",
      "no such contour OuterWall\n",
      "No lumen contour for frappe dcm slice 75\n",
      "ahaknee18tp29  exist\n",
      "cannot find dcm path for TPid 2\n",
      "ahaknee24tp29  exist\n",
      "cannot find dcm path for TPid 3\n",
      "ahaknee30tp29  exist\n",
      "cannot find dcm path for TPid 4\n",
      "ahaknee36tp29  exist\n",
      "cannot find dcm path for TPid 5\n",
      "ahaknee48tp29  exist\n",
      "cannot find dcm path for TPid 6\n",
      "ahaknee72tp29  exist\n",
      "cannot find dcm path for TPid 8\n",
      "ahaknee96tp29  exist\n",
      "cannot find dcm path for TPid 10\n",
      "ahaknee0tp29  exist\n",
      "dcm path for TPid 0 Z:/OAI Baseline/gc0/9941446/10304815\n",
      "Loading QVJ Y:/0tp29\\cascade/0/9941446/10304815R\\E10304815R_R.QVJ\n",
      "Adding QVS E10304815RS101_R.QVS\n",
      "coronal Z:/OAI Baseline/gc0/9941446/10304815/001.dcm\n",
      "copying Z:/OAI Baseline/gc0/9941446/10304815/076.dcmahaknee12tp29  exist/9941446/10304815/063.dcm\n",
      "dcm path for TPid 1 Z:/OAI 12 Months/1.C.2/9941446/20051207/10632213\n",
      "Loading QVJ Y:/12tp29\\cascade/12/9941446/20051207R\\E20051207R_R.QVJ\n",
      "Adding QVS E20051207RS101_R.QVS\n",
      "coronal Z:/OAI 12 Months/1.C.2/9941446/20051207/10632213/001.dcm\n",
      "copying Z:/OAI 12 Months/1.C.2/9941446/20051207/10632213/076.dcmahaknee18tp29  exist.2/9941446/20051207/10632213/033.dcm\n",
      "cannot find dcm path for TPid 2\n",
      "ahaknee24tp29  exist\n",
      "dcm path for TPid 3 Z:/OAI 24 Months/3.C.2/9941446/20070111/11492217\n",
      "Loading QVJ Y:/24tp29\\cascade/24/9941446/20070111R\\E20070111R_R.QVJ\n",
      "Adding QVS E20070111RS101_R.QVS\n",
      "coronal Z:/OAI 24 Months/3.C.2/9941446/20070111/11492217/001.dcm\n",
      "copying Z:/OAI 24 Months/3.C.2/9941446/20070111/11492217/076.dcmahaknee30tp29  exist\n",
      "cannot find dcm path for TPid 4\n",
      "ahaknee36tp29  exist\n",
      "dcm path for TPid 5 Z:/OAI 36 Months/5.C.1/9941446/20080124/12199708\n",
      "Loading QVJ Y:/36tp29\\cascade/36/9941446/20080124R\\E20080124R_R.QVJ\n",
      "Adding QVS E20080124RS101_R.QVS\n",
      "copying Z:/OAI 36 Months/5.C.1/9941446/20080124/12199708/075.dcmcoronal Z:/OAI 36 Months/5.C.1/9941446/20080124/12199708/076.dcm\n",
      "ahaknee48tp29  exist\n",
      "dcm path for TPid 6 Z:/OAI 48 Months/6.C.1/9941446/20090312/12758705\n",
      "Loading QVJ Y:/48tp29\\cascade/48/9941446/20090312R\\E20090312R_R.QVJ\n",
      "Adding QVS E20090312RS101_R.QVS\n",
      "copying Z:/OAI 48 Months/6.C.1/9941446/20090312/12758705/075.dcmcoronal Z:/OAI 48 Months/6.C.1/9941446/20090312/12758705/076.dcm 48 Months/6.C.1/9941446/20090312/12758705/041.dcm Z:/OAI 48 Months/6.C.1/9941446/20090312/12758705/060.dcm\n",
      "ahaknee72tp29  exist\n",
      "dcm path for TPid 8 Z:/OAI 72 Months/8.C.1/9941446/20101102/13086911\n",
      "Loading QVJ Y:/72tp29\\cascade/72/9941446/20101102R\\E20101102R_R.QVJ\n",
      "Adding QVS E20101102RS101_R.QVS\n",
      "copying Z:/OAI 72 Months/8.C.1/9941446/20101102/13086911/001.dcmno such contour OuterWall\n",
      "No lumen contour for frappe dcm slice 0\n",
      "copying Z:/OAI 72 Months/8.C.1/9941446/20101102/13086911/002.dcmno such contour OuterWall\n",
      "No lumen contour for frappe dcm slice 1\n",
      "copying Z:/OAI 72 Months/8.C.1/9941446/20101102/13086911/074.dcm Z:/OAI 72 Months/8.C.1/9941446/20101102/13086911/042.dcm Z:/OAI 72 Months/8.C.1/9941446/20101102/13086911/050.dcm Z:/OAI 72 Months/8.C.1/9941446/20101102/13086911/067.dcm Z:/OAI 72 Months/8.C.1/9941446/20101102/13086911/075.dcmcoronal Z:/OAI 72 Months/8.C.1/9941446/20101102/13086911/076.dcm\n",
      "ahaknee96tp29  exist\n",
      "dcm path for TPid 10 Z:/OAI 96 Months/10.C.1/9941446/20121101/13582718\n",
      "Loading QVJ Y:/96tp29\\cascade/96/9941446/20121101R\\E20121101R_R.QVJ\n",
      "Adding QVS E20121101RS101_R.QVS\n",
      "copying Z:/OAI 96 Months/10.C.1/9941446/20121101/13582718/075.dcmcoronal Z:/OAI 96 Months/10.C.1/9941446/20121101/13582718/076.dcm\n"
     ]
    }
   ],
   "source": [
    "# process list\n",
    "# first in TP as reference\n",
    "caselist = [\n",
    "    {'pid': '9189303','TP':[0,1,2,3,4,5,6,8,10],'TP2':[0,12,18,24,30,36,48,72,96],'side':'L'},\n",
    "    {'pid': '9941446','TP':[0,1,2,3,4,5,6,8,10],'TP2':[0,12,18,24,30,36,48,72,96],'side':'R'},\n",
    "]\n",
    "\n",
    "prepare_image_and_list(caselist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9189303L_TP0\n",
      "9189303L_TP1\n",
      "9941446R_TP0\n",
      "9941446R_TP1\n",
      "9941446R_TP3\n",
      "9941446R_TP5\n",
      "9941446R_TP6\n",
      "9941446R_TP8\n",
      "9941446R_TP10\n",
      "-> information loaded for 9 subjects\n",
      "-> Dicom images read\n",
      "-> The total time was 9.52 seconds (about 0 min)\n",
      "-> Dicom headers written\n",
      "-> The total time was 3.07 seconds (about 0 min)\n",
      "-> Image orientation changed\n",
      "-> The total time was 4.25 seconds (about 0 min)\n",
      "-> Image laterality changed for right images\n",
      "-> The total time was 2.11 seconds (about 0 min)\n",
      "-> Image origin changed\n",
      "-> _orig.mha images saved\n",
      "-> The total time was 2.94 seconds (about 0 min)\n"
     ]
    }
   ],
   "source": [
    "input_file_name           = \".\\image_list_preprocessing.txt\"\n",
    "n_of_cores                = 1 # change the number of cores according to your computer\n",
    "intensity_standardization = 0\n",
    "\n",
    "# Image information\n",
    "image_data = io.load_image_data_preprocessing(input_file_name)\n",
    "\n",
    "ref = sitk.ReadImage('../../reference/newsubject/reference.mha')\n",
    "\n",
    "# Spatial standardization\n",
    "# Step 0: Read the dicom images\n",
    "prep.read_dicom_stack(image_data, n_of_cores)\n",
    "# Save image header\n",
    "prep.print_dicom_header(image_data, n_of_cores)    # save to *.txt\n",
    "    \n",
    "# Step 1: Change orientation to RAI\n",
    "#prep.axial_to_sagittal(image_data, n_of_cores)\n",
    "prep.orientation_to_rai(image_data, n_of_cores)\n",
    "\n",
    "# Step 2: Change laterality if knee is right\n",
    "prep.flip_rl(image_data, n_of_cores)\n",
    "# Step 3: Set image origin to (0,0,0)\n",
    "prep.origin_to_zero(image_data, n_of_cores)    # Images are saved as *_orig.mha and they are anonymized\n",
    "\n",
    "# 4. Correct magnetic field inhomogeneities\n",
    "# Magnetic fields inhomogeneities create grey shades on images. This correction removes these shades. \n",
    "# This is the longest step of the processing. It can take up to 15-20 min on a standard PC or laptop\n",
    "if intensity_standardization == 1:\n",
    "    prep.field_correction(image_data, n_of_cores)\n",
    "    prep.rescale_to_range(image_data, n_of_cores)  # 5. Rescale intensities to [0 100]\n",
    "    prep.edge_preserving_smoothing(image_data, n_of_cores)  # 6. Edge preserving smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> image information loaded\n",
      "reference.mha\n",
      "-> Reference preparation completed\n",
      "-> Registration completed\n",
      "-> The total time was 1.08 seconds (about 0 min)\n",
      "-> Inversion completed\n",
      "-> The total time was 1.04 seconds (about 0 min)\n",
      "-> Warping completed\n",
      "-> The total time was 1.03 seconds (about 0 min)\n",
      "-> Registration completed\n",
      "-> The total time was 1.05 seconds (about 0 min)\n",
      "-> Inversion completed\n",
      "-> The total time was 1.02 seconds (about 0 min)\n",
      "-> Warping completed\n",
      "-> The total time was 1.06 seconds (about 0 min)\n"
     ]
    }
   ],
   "source": [
    "input_file_name = \"./image_list_newsubject.txt\"\n",
    "modality        = \"newsubject\" # use \"newsubject\", \"longitudinal\", or \"multimodal\" \n",
    "n_of_cores      = 1\n",
    "\n",
    "image_data = io.load_image_data_segmentation(modality, input_file_name)\n",
    "segm.prepare_reference(image_data)\n",
    "### NOTE!!! reference_fv is dummy!!!\n",
    "\n",
    "# Segment Bone\n",
    "# 1. Register image to reference\n",
    "segm.register_bone_to_reference(image_data, n_of_cores)\n",
    "# 2. Invert transformations\n",
    "segm.invert_bone_transformations(image_data, n_of_cores)\n",
    "# 3. Warp reference mask to moving image\n",
    "segm.warp_bone_mask(image_data, n_of_cores)\n",
    "\n",
    "# Segment cartilage\n",
    "segm.register_cartilage_to_reference(image_data, n_of_cores)\n",
    "segm.invert_cartilage_transformations(image_data, n_of_cores)\n",
    "segm.warp_cartilage_mask(image_data, n_of_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name = \"./image_list_longitudinal.txt\"\n",
    "modality        = \"longitudinal\" # use \"newsubject\", \"longitudinal\", or \"multimodal\" \n",
    "n_of_cores      = 1\n",
    "\n",
    "image_data = io.load_image_data_segmentation(modality, input_file_name)\n",
    "segm.prepare_reference(image_data)\n",
    "\n",
    "segm.register_bone_to_reference(image_data, n_of_cores)\n",
    "# segm.invert_bone_transformations(image_data, n_of_cores)\n",
    "# segm.warp_bone_mask(image_data, n_of_cores)\n",
    "\n",
    "# segm.register_vessel_to_reference(image_data, n_of_cores)\n",
    "# segm.invert_vessel_transformations(image_data, n_of_cores)\n",
    "# segm.warp_vessel_mask(image_data, n_of_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:OAIreg] *",
   "language": "python",
   "name": "conda-env-OAIreg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
