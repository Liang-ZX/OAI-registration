{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (preparing_images.py, line 6)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\student\\anaconda3\\envs\\OAIreg\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3343\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-a7aa92286d6a>\"\u001b[1;36m, line \u001b[1;32m15\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from preparing_images import prepare_image_and_list\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Zhixuan\\OAI-registration\\pykneer-yg\\pykneer\\notebooks\\preparing_images.py\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    %matplotlib inline\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "sys.path.append(r'../../pykneer')\n",
    "sys.path.append(r'../pykneer')\n",
    "import pykneer_io as io\n",
    "importlib.reload(io)\n",
    "import preprocessing_for_nb as prep\n",
    "importlib.reload(prep)\n",
    "import segmentation_sa_for_nb as segm\n",
    "importlib.reload(segm)\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from preparing_images import prepare_image_and_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name           = \".\\image_list_preprocessing.txt\"\n",
    "n_of_cores                = 1 # change the number of cores according to your computer\n",
    "intensity_standardization = 1\n",
    "\n",
    "# Image information\n",
    "image_data = io.load_image_data_preprocessing(input_file_name)\n",
    "\n",
    "ref = sitk.ReadImage('../../reference/newsubject/reference.mha')\n",
    "\n",
    "# Spatial standardization\n",
    "# Step 0: Read the dicom images\n",
    "prep.read_dicom_stack(image_data, n_of_cores)\n",
    "# Save image header\n",
    "prep.print_dicom_header(image_data, n_of_cores)    # save to *.txt\n",
    "    \n",
    "# Step 1: Change orientation to RAI\n",
    "#prep.axial_to_sagittal(image_data, n_of_cores)\n",
    "prep.orientation_to_rai(image_data, n_of_cores)\n",
    "\n",
    "# Step 2: Change laterality if knee is right\n",
    "prep.flip_rl(image_data, n_of_cores)\n",
    "# Step 3: Set image origin to (0,0,0)\n",
    "prep.origin_to_zero(image_data, n_of_cores)    # Images are saved as *_orig.mha and they are anonymized\n",
    "\n",
    "# 4. Correct magnetic field inhomogeneities\n",
    "# Magnetic fields inhomogeneities create grey shades on images. This correction removes these shades. \n",
    "# This is the longest step of the processing. It can take up to 15-20 min on a standard PC or laptop\n",
    "if intensity_standardization == 1:\n",
    "    prep.field_correction(image_data, n_of_cores)\n",
    "    \n",
    "# 5. Rescale intensities to [0 100]\n",
    "if intensity_standardization == 1:\n",
    "    prep.rescale_to_range(image_data, n_of_cores) \n",
    "    \n",
    "# 6. Edge preserving smoothing\n",
    "if intensity_standardization == 1:\n",
    "    prep.edge_preserving_smoothing(image_data, n_of_cores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name = \"./image_list_newsubject.txt\"\n",
    "modality        = \"newsubject\" # use \"newsubject\", \"longitudinal\", or \"multimodal\" \n",
    "n_of_cores      = 1\n",
    "\n",
    "image_data = io.load_image_data_segmentation(modality, input_file_name)\n",
    "segm.prepare_reference(image_data)\n",
    "### NOTE!!! reference_fv is dummy!!!\n",
    "\n",
    "# Segment Bone\n",
    "# 1. Register image to reference\n",
    "segm.register_bone_to_reference(image_data, n_of_cores)\n",
    "# 2. Invert transformations\n",
    "segm.invert_bone_transformations(image_data, n_of_cores)\n",
    "# 3. Warp reference mask to moving image\n",
    "segm.warp_bone_mask(image_data, n_of_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name = \"./image_list_longitudinal.txt\"\n",
    "modality        = \"longitudinal\" # use \"newsubject\", \"longitudinal\", or \"multimodal\" \n",
    "n_of_cores      = 1\n",
    "\n",
    "image_data = io.load_image_data_segmentation(modality, input_file_name)\n",
    "segm.prepare_reference(image_data)\n",
    "\n",
    "segm.register_bone_to_reference(image_data, n_of_cores)\n",
    "# segm.invert_bone_transformations(image_data, n_of_cores)\n",
    "# segm.warp_bone_mask(image_data, n_of_cores)\n",
    "\n",
    "# segm.register_vessel_to_reference(image_data, n_of_cores)\n",
    "# segm.invert_vessel_transformations(image_data, n_of_cores)\n",
    "# segm.warp_vessel_mask(image_data, n_of_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:OAIreg] *",
   "language": "python",
   "name": "conda-env-OAIreg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
